{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; # os.environ['ACCELERATE_DISABLE_RICH'] = \"1\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "\n",
    "from typing import Optional, Union, List, Tuple, Callable, Any\n",
    "\n",
    "from dataclasses import dataclass, replace\n",
    "import numpy as np\n",
    "import einops\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import importlib\n",
    "import plotly_utils\n",
    "import utils\n",
    "\n",
    "importlib.reload(plotly_utils)\n",
    "importlib.reload(utils)\n",
    "\n",
    "from utils import *\n",
    "from plotly_utils import imshow, line, hist, scatter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = 'cuda'\n",
    "else:\n",
    "  DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n",
      "tensor([[3, 2, 1, 3, 3, 0],\n",
      "        [4, 1, 3, 1, 1, 0],\n",
      "        [3, 2, 4, 1, 1, 0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "cfg = HookedTransformerConfig(\n",
    "    n_layers=2,\n",
    "    d_model=16,\n",
    "    d_head=8,\n",
    "    n_heads=2,\n",
    "    d_mlp=4*16,\n",
    "    d_vocab=10,\n",
    "    n_ctx=6,\n",
    "    act_fn=\"relu\",\n",
    "    normalization_type=None,\n",
    ")\n",
    "\n",
    "SEED=1\n",
    "torch.manual_seed(SEED)\n",
    "model = HookedTransformer(cfg).to(DEVICE)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "dataset = MaxDataset(size=10000, config=cfg, device=DEVICE)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, dataloader, optimizer, epochs=1):\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            batch = batch.to(DEVICE)\n",
    "            labels = batch.max(dim=-1).values\n",
    "            logits = model(batch)\n",
    "            loss = F.cross_entropy(logits[:, -1], labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "train(model, dataloader, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.W_E torch.Size([10, 16])\n",
      "pos_embed.W_pos torch.Size([6, 16])\n",
      "blocks.0.attn.W_Q torch.Size([2, 16, 8])\n",
      "blocks.0.attn.W_K torch.Size([2, 16, 8])\n",
      "blocks.0.attn.W_V torch.Size([2, 16, 8])\n",
      "blocks.0.attn.W_O torch.Size([2, 8, 16])\n",
      "blocks.0.attn.b_Q torch.Size([2, 8])\n",
      "blocks.0.attn.b_K torch.Size([2, 8])\n",
      "blocks.0.attn.b_V torch.Size([2, 8])\n",
      "blocks.0.attn.b_O torch.Size([16])\n",
      "blocks.0.mlp.W_in torch.Size([16, 64])\n",
      "blocks.0.mlp.b_in torch.Size([64])\n",
      "blocks.0.mlp.W_out torch.Size([64, 16])\n",
      "blocks.0.mlp.b_out torch.Size([16])\n",
      "blocks.1.attn.W_Q torch.Size([2, 16, 8])\n",
      "blocks.1.attn.W_K torch.Size([2, 16, 8])\n",
      "blocks.1.attn.W_V torch.Size([2, 16, 8])\n",
      "blocks.1.attn.W_O torch.Size([2, 8, 16])\n",
      "blocks.1.attn.b_Q torch.Size([2, 8])\n",
      "blocks.1.attn.b_K torch.Size([2, 8])\n",
      "blocks.1.attn.b_V torch.Size([2, 8])\n",
      "blocks.1.attn.b_O torch.Size([16])\n",
      "blocks.1.mlp.W_in torch.Size([16, 64])\n",
      "blocks.1.mlp.b_in torch.Size([64])\n",
      "blocks.1.mlp.W_out torch.Size([64, 16])\n",
      "blocks.1.mlp.b_out torch.Size([16])\n",
      "unembed.W_U torch.Size([16, 10])\n",
      "unembed.b_U torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# model(torch.tensor([[1, 2, 3, 3, 3, 0]]).to(DEVICE))[:, -1].argmax(dim=-1)\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
